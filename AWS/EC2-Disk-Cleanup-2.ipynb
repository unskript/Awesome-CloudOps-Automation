{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "bf364c84",
            "metadata": {},
            "source": [
                "\n",
                "<img src=\"https://unskript.com/assets/favicon.png\" alt=\"unSkript.com\" width=\"100\" height=\"100\"/> \n",
                "<h1> unSkript Runbooks </h1>\n",
                "<div class=\"alert alert-block alert-success\">\n",
                "    <b> This runbook demonstrates How to Cleanup EC2 Disks using unSkript legos.</b>\n",
                "</div>\n",
                "\n",
                "<br>\n",
                "\n",
                "<center><h2>EC2 Disk Cleanup</h2></center>\n",
                "\n",
                "# Steps Overview\n",
                "    1) Find IP address of instance\n",
                "    2) Find large files in specified path\n",
                "    3) Map remote file names to S3 object names\n",
                "    4) Back up files to S3\n",
                "    5) Delete files from instance\n",
                "    6) Send message to Slack"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "683caff0",
            "metadata": {},
            "source": [
                "Here we will use unSkript Get AWS Instance Details Lego. This lego takes instance_id and region as input. This inputs is used to findout all the details of EC2 instance."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "10426f2b",
            "metadata": {},
            "outputs": [],
            "source": [
                "##\n",
                "# Copyright (c) 2021 unSkript, Inc\n",
                "# All rights reserved.\n",
                "##\n",
                "from pydantic import BaseModel, Field\n",
                "\n",
                "\n",
                "from beartype import beartype\n",
                "@beartype\n",
                "def aws_get_instance_details(\n",
                "    handle,\n",
                "    instance_id: str,\n",
                "    region: str,\n",
                "):\n",
                "\n",
                "    ec2client = handle.client('ec2', region_name=region)\n",
                "    instances = []\n",
                "    response = ec2client.describe_instances(\n",
                "        Filters=[{\"Name\": \"instance-id\", \"Values\": [instance_id]}])\n",
                "    for reservation in response[\"Reservations\"]:\n",
                "        for instance in reservation[\"Instances\"]:\n",
                "            instances.append(instance)\n",
                "\n",
                "    return instances[0]\n",
                "\n",
                "\n",
                "task = Task(Workflow())\n",
                "task.configure(inputParamsJson='''{\n",
                "    \"instance_id\": \"instance_id\",\n",
                "    \"region\": \"region\"\n",
                "    }''')\n",
                "task.configure(outputName=\"InstanceDetails\")\n",
                "\n",
                "(err, hdl, args) = task.validate(vars=vars())\n",
                "if err is None:\n",
                "    task.output = task.execute(aws_get_instance_details, hdl=hdl, args=args)\n",
                "    if task.output_name != None:\n",
                "        globals().update({task.output_name: task.output[0]})\n",
                "\n",
                "if hasattr(task, 'output'):\n",
                "    if isinstance(task.output, (list, tuple)):\n",
                "        for item in task.output:\n",
                "            print(f'item: {item}')\n",
                "    elif isinstance(task.output, dict):\n",
                "        for item in task.output.items():\n",
                "            print(f'item: {item}')\n",
                "    else:\n",
                "        print(f'Output for {task.name}')\n",
                "        print(task.output)\n",
                "    w.tasks[task.name]= task.output\n",
                "    ssh_ip = InstanceDetails.get('PrivateIPAddress')"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "db3d320b",
            "metadata": {},
            "source": [
                "Here we will use unSkript SSH: Locate large files on host Lego. This lego takes host, inspect_folder, threshold, sudo and count as input. This inputs is used to scans the file system on a given host and returns a dict of large files. The command used to perform the scan is \\\"find inspect_folder -type f -exec du -sk '{}' + | sort -rh | head -n count\\."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "b2fa4959",
            "metadata": {},
            "outputs": [],
            "source": [
                "##\n",
                "# Copyright (c) 2021 unSkript, Inc\n",
                "# All rights reserved.\n",
                "##\n",
                "import json\n",
                "import tempfile\n",
                "import os\n",
                "from pydantic import BaseModel, Field\n",
                "from pssh.clients import ParallelSSHClient\n",
                "from typing import List, Optional\n",
                "from unskript.connectors import ssh\n",
                "\n",
                "from unskript.legos.cellparams import CellParams\n",
                "from unskript import connectors\n",
                "\n",
                "\n",
                "from beartype import beartype\n",
                "@beartype\n",
                "def ssh_find_large_files(\n",
                "    sshClient,\n",
                "    host: str,\n",
                "    inspect_folder: str,\n",
                "    threshold: int = 0,\n",
                "    sudo: bool = False,\n",
                "    count: int = 10) -> dict:\n",
                "\n",
                "    client = sshClient([host])\n",
                "\n",
                "    # find size in Kb\n",
                "    command = \"find \" + inspect_folder + \\\n",
                "        \" -type f -exec du -sm '{}' + | sort -rh | head -n \" + str(count)\n",
                "    runCommandOutput = client.run_command(command=command, sudo=sudo)\n",
                "    client.join()\n",
                "    res = {}\n",
                "\n",
                "    for host_output in runCommandOutput:\n",
                "        for line in host_output.stdout:\n",
                "            # line is of the form {size} {fullfilename}\n",
                "            (size, filename) = line.split()\n",
                "            if int(size) > threshold:\n",
                "                res[filename] = int(size)\n",
                "\n",
                "    return res\n",
                "\n",
                "\n",
                "task = Task(Workflow())\n",
                "task.configure(inputParamsJson='''{\n",
                "    \"count\": \"10\",\n",
                "    \"host\": \"ssh_ip\",\n",
                "    \"inspect_folder\": \"dirs_to_anaylze\",\n",
                "    \"sudo\": \"False\",\n",
                "    \"threshold\": \"Threshold\"\n",
                "    }''')\n",
                "task.configure(outputName=\"FileLocation\")\n",
                "\n",
                "(err, hdl, args) = task.validate(vars=vars())\n",
                "if err is None:\n",
                "    task.output = task.execute(ssh_find_large_files, hdl=hdl, args=args)\n",
                "    if task.output_name != None:\n",
                "        globals().update({task.output_name: task.output[0]})\n",
                "\n",
                "if hasattr(task, 'output'):\n",
                "    if isinstance(task.output, (list, tuple)):\n",
                "        for item in task.output:\n",
                "            print(f'item: {item}')\n",
                "    elif isinstance(task.output, dict):\n",
                "        for item in task.output.items():\n",
                "            print(f'item: {item}')\n",
                "    else:\n",
                "        print(f'Output for {task.name}')\n",
                "        print(task.output)\n",
                "    w.tasks[task.name]= task.output"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "26f58208",
            "metadata": {},
            "outputs": [],
            "source": [
                "remote_files = [x for x in FileLocation.keys()]\n",
                "if len(remote_files) == 0:\n",
                "    print(\"No files to process, exiting\")\n",
                "    if hasattr(Workflow(), \"Done\"):\n",
                "        Workflow().Done()\n",
                "\n",
                "local_files = [ \"/tmp/\" + x.lstrip(\"/\").replace(\"/\", \"_\") for x in remote_files ]\n",
                "mapping = []\n",
                "for i in range(len(remote_files)):\n",
                "    mapping.append( {'remote': remote_files[i], 'local': local_files[i]} )\n",
                "print(json.dumps(mapping, indent=2))\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "fa9d4401",
            "metadata": {},
            "source": [
                "Here we will use unSkript SCP: Remote file transfer over SSH Lego. This lego takes host, remote_file, local_file and direction as input. This inputs is used to Copy files from or to remote host. Files are copied over SCP."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "5b279ca0",
            "metadata": {},
            "outputs": [],
            "source": [
                "##\n",
                "# Copyright (c) 2021 unSkript, Inc\n",
                "# All rights reserved.\n",
                "##\n",
                "\n",
                "from pydantic import BaseModel, Field\n",
                "from gevent import joinall\n",
                "\n",
                "\n",
                "from beartype import beartype\n",
                "@beartype\n",
                "def ssh_scp(\n",
                "        sshClient,\n",
                "        host: str,\n",
                "        remote_file: str,\n",
                "        local_file: str,\n",
                "        direction: bool = True) -> bool:\n",
                "\n",
                "    client = sshClient([host])\n",
                "    copy_args = [{'local_file': local_file, 'remote_file': remote_file}]\n",
                "\n",
                "    if direction is True:\n",
                "        cmds = client.copy_remote_file(remote_file=remote_file, local_file=local_file,\n",
                "                                       recurse=False,\n",
                "                                       suffix_separator=\"\", copy_args=copy_args,\n",
                "                                       encoding='utf-8')\n",
                "\n",
                "    else:\n",
                "        cmds = client.copy_file(local_file=local_file, remote_file=remote_file,\n",
                "                                recurse=False, copy_args=None)\n",
                "\n",
                "    try:\n",
                "        joinall(cmds, raise_error=True)\n",
                "        if direction is True:\n",
                "            print(f\"Successfully copied file {host}://{remote_file} to {local_file}\")\n",
                "        else:\n",
                "            print(f\"Successfully copied file {local_file} to {host}://{remote_file}\")\n",
                "\n",
                "    except Exception as e:\n",
                "        print(f\"Error encountered while copying files {e}\")\n",
                "        return False\n",
                "\n",
                "    return True\n",
                "\n",
                "\n",
                "task = Task(Workflow())\n",
                "task.configure(inputParamsJson='''{\n",
                "    \"direction\": \"True\",\n",
                "    \"host\": \"ssh_ip\",\n",
                "    \"local_file\": \"iter.get(\\\\\"local\\\\\")\",\n",
                "    \"remote_file\": \"iter.get(\\\\\"remote\\\\\")\"\n",
                "    }''')\n",
                "\n",
                "(err, hdl, args) = task.validate(vars=vars())\n",
                "if err is None:\n",
                "    task.output = task.execute(ssh_scp, hdl=hdl, args=args)\n",
                "    if task.output_name != None:\n",
                "        globals().update({task.output_name: task.output[0]})\n",
                "\n",
                "if hasattr(task, 'output'):\n",
                "    if isinstance(task.output, (list, tuple)):\n",
                "        for item in task.output:\n",
                "            print(f'item: {item}')\n",
                "    elif isinstance(task.output, dict):\n",
                "        for item in task.output.items():\n",
                "            print(f'item: {item}')\n",
                "    else:\n",
                "        print(f'Output for {task.name}')\n",
                "        print(task.output)\n",
                "    w.tasks[task.name]= task.output"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "1f8205ef",
            "metadata": {},
            "source": [
                "Here we will use unSkript Upload file to S3 Lego. This lego takes bucketName, file and prefix as input. This inputs is used to Upload a local file to S3 bucket."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "0f4d8bbd",
            "metadata": {},
            "outputs": [],
            "source": [
                "##\n",
                "# Copyright (c) 2021 unSkript, Inc\n",
                "# All rights reserved.\n",
                "##\n",
                "\n",
                "\n",
                "from pydantic import BaseModel, Field\n",
                "\n",
                "\n",
                "from beartype import beartype\n",
                "@beartype\n",
                "def aws_upload_file_to_s3(handle, bucketName: str, file: str, prefix: str = \"\"):\n",
                "\n",
                "    s3 = handle.client('s3')\n",
                "    objName = prefix + file.split(\"/\")[-1]\n",
                "    try:\n",
                "        with open(file, \"rb\") as f:\n",
                "            s3.upload_fileobj(f, bucketName, objName)\n",
                "    except Exception as e:\n",
                "        print(f\"Error: {e}\")\n",
                "        raise e\n",
                "\n",
                "    print(f\"Successfully copied {file} to bucket:{bucketName} object:{objName}\")\n",
                "    return None\n",
                "\n",
                "\n",
                "task = Task(Workflow())\n",
                "task.configure(inputParamsJson='''{\n",
                "    \"bucketName\": \"Bucket\",\n",
                "    \"file\": \"iter.get(\\\\\"local\\\\\")\",\n",
                "    \"prefix\": \"prefix or f\\\\\"{instance_id}/{str(datetime.date.today())}/\\\\\"\"\n",
                "    }''')\n",
                "\n",
                "task.configure(iterJson='''{\n",
                "    \"iter_enabled\": true,\n",
                "    \"iter_list_is_const\": false,\n",
                "    \"iter_list\": \"mapping\",\n",
                "    \"iter_parameter\": \"\"\n",
                "    }''')\n",
                "\n",
                "(err, hdl, args) = task.validate(vars=vars())\n",
                "if err is None:\n",
                "    task.output = task.execute(aws_upload_file_to_s3, hdl=hdl, args=args)\n",
                "    if task.output_name != None:\n",
                "        globals().update({task.output_name: task.output[0]})\n",
                "\n",
                "if hasattr(task, 'output'):\n",
                "    if isinstance(task.output, (list, tuple)):\n",
                "        for item in task.output:\n",
                "            print(f'item: {item}')\n",
                "    elif isinstance(task.output, dict):\n",
                "        for item in task.output.items():\n",
                "            print(f'item: {item}')\n",
                "    else:\n",
                "        print(f'Output for {task.name}')\n",
                "        print(task.output)\n",
                "    w.tasks[task.name]= task.output"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "f109e639",
            "metadata": {},
            "source": [
                "Here we will use unSkript SSH Execute Remote Command Lego. This lego takes hosts, command and sudo as input. This inputs is used to SSH Execute Remote Command."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "a7b4da92",
            "metadata": {},
            "outputs": [],
            "source": [
                "##\n",
                "# Copyright (c) 2021 unSkript, Inc\n",
                "# All rights reserved.\n",
                "##\n",
                "import json\n",
                "import tempfile\n",
                "import os\n",
                "from pydantic import BaseModel, Field\n",
                "from pssh.clients import ParallelSSHClient\n",
                "from typing import List, Optional\n",
                "from unskript.connectors import ssh\n",
                "\n",
                "from unskript.legos.cellparams import CellParams\n",
                "from unskript import connectors\n",
                "\n",
                "\n",
                "from beartype import beartype\n",
                "@beartype\n",
                "def ssh_execute_remote_command(sshClient, hosts: List[str], command: str, sudo: bool = False):\n",
                "\n",
                "    client = sshClient(hosts)\n",
                "    runCommandOutput = client.run_command(command=command, sudo=sudo)\n",
                "    client.join()\n",
                "    res = {}\n",
                "\n",
                "    for host_output in runCommandOutput:\n",
                "        hostname = host_output.host\n",
                "        output = []\n",
                "        for line in host_output.stdout:\n",
                "            output.append(line)\n",
                "        res[hostname] = output\n",
                "\n",
                "        o = \"\\n\".join(output)\n",
                "        print(f\"Output from host {hostname}\\n{o}\\n\")\n",
                "\n",
                "    return res\n",
                "\n",
                "\n",
                "task = Task(Workflow())\n",
                "task.configure(inputParamsJson='''{\n",
                "    \"command\": \"\\\\\"rm -v \\\\\" + \\\\\" \\\\\".join(remote_files)\",\n",
                "    \"hosts\": \"[ ssh_ip ]\",\n",
                "    \"sudo\": \"False\"\n",
                "    }''')\n",
                "\n",
                "(err, hdl, args) = task.validate(vars=vars())\n",
                "if err is None:\n",
                "    task.output = task.execute(ssh_execute_remote_command, hdl=hdl, args=args)\n",
                "    if task.output_name != None:\n",
                "        globals().update({task.output_name: task.output[0]})\n",
                "\n",
                "if hasattr(task, 'output'):\n",
                "    if isinstance(task.output, (list, tuple)):\n",
                "        for item in task.output:\n",
                "            print(f'item: {item}')\n",
                "    elif isinstance(task.output, dict):\n",
                "        for item in task.output.items():\n",
                "            print(f'item: {item}')\n",
                "    else:\n",
                "        print(f'Output for {task.name}')\n",
                "        print(task.output)\n",
                "    w.tasks[task.name]= task.output"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "b8df308a",
            "metadata": {},
            "outputs": [],
            "source": [
                "from subprocess import PIPE, run\n",
                "\n",
                "o = run(f\"rm -fv {' '.join(local_files)}\", stdout=PIPE, stderr=PIPE, universal_newlines=True, shell=True)\n",
                "print(o.stdout)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "416f1944",
            "metadata": {},
            "source": [
                "Here we will use unSkript Post Slack Message Lego. This lego takes channel: str and message: str as input. This inputs is used to post the message to the slack channel."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "cd50ba85",
            "metadata": {},
            "outputs": [],
            "source": [
                "##\n",
                "# Copyright (c) 2021 unSkript, Inc\n",
                "# All rights reserved.\n",
                "##\n",
                "\n",
                "import pprint\n",
                "\n",
                "from pydantic import BaseModel, Field\n",
                "from slack_sdk import WebClient\n",
                "from slack_sdk.errors import SlackApiError\n",
                "\n",
                "pp = pprint.PrettyPrinter(indent=2)\n",
                "\n",
                "\n",
                "from beartype import beartype\n",
                "def legoPrinter(func):\n",
                "    def Printer(*args, **kwargs):\n",
                "        output = func(*args, **kwargs)\n",
                "        if output:\n",
                "            channel = kwargs[\"channel\"]\n",
                "            pp.pprint(print(f\"Message sent to Slack channel {channel}\"))\n",
                "        return output\n",
                "    return Printer\n",
                "\n",
                "\n",
                "@legoPrinter\n",
                "@beartype\n",
                "def slack_post_message(\n",
                "        handle: WebClient,\n",
                "        channel: str,\n",
                "        message: str) -> bool:\n",
                "\n",
                "    try:\n",
                "        response = handle.chat_postMessage(\n",
                "            channel=channel,\n",
                "            text=message)\n",
                "        return True\n",
                "    except SlackApiError as e:\n",
                "        print(\"\\n\\n\")\n",
                "        pp.pprint(\n",
                "            f\"Failed sending message to slack channel {channel}, Error: {e.response['error']}\")\n",
                "        return False\n",
                "    except Exception as e:\n",
                "        print(\"\\n\\n\")\n",
                "        pp.pprint(\n",
                "            f\"Failed sending message to slack channel {channel}, Error: {e.__str__()}\")\n",
                "        return False\n",
                "\n",
                "\n",
                "task = Task(Workflow())\n",
                "task.configure(inputParamsJson='''{\n",
                "    \"message\": \"f\\\\\"Deleted {len(remote_files)} files from host {ssh_ip}\\\\\"\"\n",
                "    }''')\n",
                "\n",
                "(err, hdl, args) = task.validate(vars=vars())\n",
                "if err is None:\n",
                "    task.output = task.execute(slack_post_message, hdl=hdl, args=args)\n",
                "    if task.output_name != None:\n",
                "        globals().update({task.output_name: task.output[0]})"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "1006351c",
            "metadata": {},
            "source": [
                "### Conclusion\n",
                "In this Runbook, we demonstrated the use of unSkript's AWS and SSH legos to perform AWS and SSH actions and this runbook locates large files in a given path inside an EC2 instance and backs them up into a given S3 bucket. Afterwards, it deletes the files backed up and send a message on slack. To view the full platform capabilities of unSkript please visit https://unskript.com"
            ]
        }
    ],
    "metadata": {
        "execution_data": {
            "environment_id": "dba3932f-3118-4ab0-b92c-70fa56402037",
            "environment_name": "SingleAMI",
            "execution_id": "",
            "inputs_for_searched_lego": "",
            "notebook_id": "workflow.ipynb",
            "parameters": [
                "Bucket",
                "Threshold",
                "dirs_to_anaylze",
                "instance_id",
                "prefix",
                "region"
            ],
            "runbook_name": "JRRunbook",
            "search_string": "",
            "show_tool_tip": false,
            "tenant_id": "8b3c7148-2d57-4b89-84d3-d59f6c792b0c",
            "tenant_url": "https://tenant-amit.dev.unskript.io",
            "user_email_id": "amit@unskript.com",
            "workflow_id": "755dbe40-22d7-4b70-a04d-31d34bb04e4a"
        },
        "kernelspec": {
            "display_name": "Python 3.10.4 ('test')",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.4"
        },
        "parameterSchema": {
            "properties": {
                "Bucket": {
                    "default": "unskript-dev",
                    "description": "Bucket for uploading large files",
                    "title": "Bucket",
                    "type": "string"
                },
                "Threshold": {
                    "default": 100,
                    "description": "Threshold on file size (in Mb)",
                    "title": "Threshold",
                    "type": "number"
                },
                "dirs_to_anaylze": {
                    "default": "/home",
                    "description": "Root for directories to be analyzed for large files",
                    "title": "dirs_to_anaylze",
                    "type": "string"
                },
                "instance_id": {
                    "default": "i-02127703d2b6d3f56",
                    "description": "EC2 Instance",
                    "title": "instance_id",
                    "type": "string"
                },
                "prefix": {
                    "default": "test/",
                    "description": "Prefix to use while uploading to S3 (default: <instance>/<date>)",
                    "title": "prefix",
                    "type": "string"
                },
                "region": {
                    "default": "us-west-2",
                    "description": "AWS Region",
                    "title": "region",
                    "type": "string"
                }
            },
            "required": [],
            "title": "Schema",
            "type": "object"
        },
        "parameterValues": {
            "Bucket": "unskript-dev",
            "Threshold": null,
            "dirs_to_anaylze": "/home",
            "instance_id": "i-02127703d2b6d3f56",
            "prefix": "test/",
            "region": "us-west-2"
        },
        "vscode": {
            "interpreter": {
                "hash": "4bbe27a4ef15b3fedcd2e654ecc35fc9b20de5c40077b83d62753092d26a6932"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
